<!DOCTYPE HTML>
<html>

<head>
	<link rel="bookmark"  type="image/x-icon"  href="/img/logo_miccall.png"/>
	<link rel="shortcut icon" href="/img/logo_miccall.png">
	
			    <title>
    Zima Blue's blog
    </title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="/css/mic_main.css" />
    <link rel="stylesheet" href="/css/dropdownMenu.css" />
    <meta name="keywords" content="miccall" />
    
    	<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
	 
    <noscript>
        <link rel="stylesheet" href="/css/noscript.css" />
    </noscript>
    <style type="text/css">
        body:before {
          content: ' ';
          position: fixed;
          top: 0;
          background: url('/img/bg.jpg') center 0 no-repeat;
          right: 0;
          bottom: 0;
          left: 0;
          background-size: cover; 
        }
    </style>

			    
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script async type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


    <script src="/js/jquery.min.js"></script>
    <script src="/js/jquery.scrollex.min.js"></script>
    <script src="/js/jquery.scrolly.min.js"></script>
    <script src="/js/skel.min.js"></script>
    <script src="/js/util.js"></script>
    <script src="/js/main.js"></script>
	
<meta name="generator" content="Hexo 5.0.0"></head>
    
		
<!-- Layouts -->



<!--  代码渲染  -->
<link rel="stylesheet" href="/css/prism_coy.css" />
<link rel="stylesheet" href="/css/typo.css" />
<!-- 文章页 -->
<body class="is-loading">
    <!-- Wrapper 外包 s-->
    <div id="wrapper" class="fade-in">
        <!-- Intro 头部显示 s -->
        <!-- Intro 头部显示 e -->
        <!-- Header 头部logo start -->
        <header id="header">
    <a href="/" class="logo">MICCALL</a>
</header>
        <!-- Nav 导航条 start -->
        <nav id="nav" class="special" >
            <ul class="menu links" >
			<!-- Homepage  主页  --> 
			<li >
	            <a href="/" rel="nofollow">主页</a>
	        </li>
			<!-- categories_name  分类   --> 
	        
	        <li class="active">
	            <a href="#s1">分类</a>
	                    <ul class="submenu">
	                        <li>
	                        
	                    </ul>
	        </li>
	        
	        <!-- archives  归档   --> 
	        
	        
		        <!-- Pages 自定义   -->
		        


            </ul>
            <!-- icons 图标   -->
			<ul class="icons">
                    
                    <li>
                        <a title="github" href="https://github.com/miccall" target="_blank" rel="noopener">
                            <i class="icon fa fa-github"></i>
                        </a>
                    </li>
                    
                    <li>
                        <a title="500px" href="http://500px.com" target="_blank" rel="noopener">
                            <i class="icon fa fa-500px"></i>
                        </a>
                    </li>
                    
			</ul>
</nav>

        <div id="main" >
            <div class ="post_page_title_img" style="height: 25rem;background-image: url();background-position: center; background-repeat:no-repeat; background-size:cover;-moz-background-size:cover;overflow:hidden;" >
                <a href="#" style="padding: 4rem 4rem 2rem 4rem ;"><h2 >sklearn广义线性模型</h2></a>
            </div>
            <!-- Post -->
            <div class="typo" style="padding: 3rem;">
                <h1 id="广义线性模型"><a href="#广义线性模型" class="headerlink" title="广义线性模型"></a>广义线性模型</h1><h2 id="普通最小二乘法"><a href="#普通最小二乘法" class="headerlink" title="普通最小二乘法"></a>普通最小二乘法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"></span><br><span class="line">reg = linear_model.LinearRegression()</span><br><span class="line">reg.fit([[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>]], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line"><span class="comment"># y=x+1</span></span><br><span class="line">print(reg.coef_)  <span class="comment"># 参数值</span></span><br><span class="line">print(reg.intercept_)  <span class="comment"># 截距</span></span><br><span class="line">print(reg.predict([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">3</span>]]))  <span class="comment"># 想要预测的数据，放到一个列表中</span></span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">[<span class="number">0.5</span> <span class="number">0.5</span>]</span><br><span class="line"><span class="number">5.551115123125783e-17</span></span><br><span class="line">[<span class="number">1.5</span> <span class="number">2.5</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LinearRegression(copy_X=<span class="literal">True</span>, fit_intercept=<span class="literal">True</span>, n_jobs=<span class="number">1</span>, normalize=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><p>fit_intercept：bool, default=True</p>
<p>是否计算截距</p>
</li>
<li><p><strong>normalize</strong>：bool, default=False</p>
<p>是否将数据标准化</p>
</li>
<li><p><strong>copy_X</strong>：bool, default=True</p>
<p>如果为True，将复制X；否则为X。否则，它可能会被覆盖。</p>
</li>
<li><p><strong>n_jobs</strong>：int, default=None</p>
<p>使用进程的数量，与电脑的CPU有关，-1表示使用所有处理器</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fit(self, X, y, sample_weight=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

<p>X是自变量，y是每个自变量所对应的因变量，sample_weight是每个自变量的权重</p>
<h2 id="岭回归"><a href="#岭回归" class="headerlink" title="岭回归"></a>岭回归</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"></span><br><span class="line">reg = linear_model.Ridge(alpha=<span class="number">.5</span>)  <span class="comment"># alpha参数大于0</span></span><br><span class="line">reg.fit([[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>]], [<span class="number">0</span>, <span class="number">.1</span>, <span class="number">1</span>])</span><br><span class="line">print(reg.coef_, reg.intercept_, reg.predict([[<span class="number">3</span>, <span class="number">3</span>]]))</span><br></pre></td></tr></table></figure>

<p>除了创建时不同，与其他线性模型一样， <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge"><code>Ridge</code></a> 用 <code>fit</code> 方法完成拟合，并将模型系数 ω 存储在其 <code>coef_</code> 成员中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Ridge(alpha=<span class="number">1.0</span>, fit_intercept=<span class="literal">True</span>, normalize=<span class="literal">False</span>, copy_X=<span class="literal">True</span>, max_iter=<span class="literal">None</span>, tol=<span class="number">0.001</span>, solver=<span class="string">&#x27;auto&#x27;</span>, random_state=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><p><strong>alpha</strong>：float, ndarray of shape (n_targets), default=1.0</p>
<p>正则化参数，传入的是正浮点数，如果有多个惩罚项则传入数组</p>
</li>
<li><p><strong>fit_intercept</strong>：boolean, optional, default True</p>
<p>是否计算截距。如果为False，对数据进行去中心化处理。</p>
</li>
<li><p><strong>normalize</strong>：boolean, optional, default False</p>
<p>对数据X进行标准化</p>
</li>
<li><p><strong>max_iter</strong>：int, default=None</p>
<p>共轭梯度求解器的最大迭代次数。</p>
</li>
<li><p><strong>tol：</strong>float, optional</p>
</li>
</ul>
<p>　　优化容忍度：如果更新大于tol，继续优化，直到小于tol。</p>
<ul>
<li><p><strong>solver</strong>：{‘auto’, ‘svd’, ‘cholesky’, ‘lsqr’, ‘sparse_cg’, ‘sag’, ‘saga’}, default=’auto’</p>
<p>参数计算方式</p>
<p>auto：根据数据类型自动选择求解器。</p>
<p>svd：使用X的奇异值分解来计算Ridge系数，对于奇异矩阵，比cholesky更稳定。</p>
<p>cholesky：使用标准的scipy.linalg.solve函数来获取封闭形式的解决方案。</p>
<p>sparse_cg：使用scipy.sparse.linalg.cg中的共轭梯度求解器。作为一种迭代算法，对于大规模数据（可以设置tol和max_iter），此求解器比cholesky更合适。</p>
<p> lsqr：使用专用的正则化最小二乘例程scipy.sparse.linalg.lsqr。它是最快的，并且使用迭代过程。</p>
<p> sag和saga：sag使用随机平均梯度下降，saga使用经过改进的无偏版本SAGA。两种方法都使用迭代过程，并且当n_samples和n_features都较大时，通常比其他求解器更快。请注意，只有在比例大致相同的要素上才能确保“ sag”和“ saga”快速收敛。您可以使用sklearn.preprocessing中的缩放器对数据进行预处理。</p>
</li>
<li><p><strong>random_state：</strong>int, RandomState instance or None, optional, default None</p>
<p>伪随机数发生器种子，随机选择特征来更新模型。如果为int，random_state即为随机数发生器使用的种子；如果为RandomState实例，random_state即为随机数发生器；如果为None，随机数发生器为np.random使用的随机数发生器实例。该参数仅当selection=‘random’时使用。</p>
</li>
</ul>
<h5 id="岭回归所解决的问题："><a href="#岭回归所解决的问题：" class="headerlink" title="岭回归所解决的问题："></a><strong>岭回归所解决的问题：</strong></h5><p>普通最小二乘法会在实际应用中遇到以下问题：</p>
<p>（1）数据样本数比特征数少的情况，矩阵的逆不能直接计算，当求n元一次方程组时，需要有n个方程才可以求出唯一解，也就是说最少需要n个样本。</p>
<p>（2）即使样本数多于特征数，若特征高度相关，X^T^X的逆依然无法计算。</p>
<p>   (3)  过拟合</p>
<h5 id="设置正则化参数：广义交叉验证"><a href="#设置正则化参数：广义交叉验证" class="headerlink" title="设置正则化参数：广义交叉验证"></a>设置正则化参数：广义交叉验证</h5><p><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV"><code>RidgeCV</code></a> 通过内置的关于的 alpha 参数的交叉验证来实现岭回归。 </p>
<p>默认为 Generalized Cross-Validation(广义交叉验证 GCV)，这是一种有效的留一验证方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line">reg = linear_model.RidgeCV(alphas=[<span class="number">0.1</span>, <span class="number">1.0</span>, <span class="number">10.0</span>])</span><br><span class="line">reg.fit([[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>]], [<span class="number">0</span>, <span class="number">0.1</span>, <span class="number">1</span>])</span><br><span class="line">print(reg.alpha_)  <span class="comment"># 得出的正则化参数</span></span><br></pre></td></tr></table></figure>

<p>指定cv属性的值将触发(通过GridSearchCV的)交叉验证。例如，cv=10将触发10折的交叉验证，而不是广义交叉验证(GCV)。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RidgeCV(alphas=(<span class="number">0.1</span>, <span class="number">1.0</span>, <span class="number">10.0</span>), fit_intercept=<span class="literal">True</span>, normalize=<span class="literal">False</span>, scoring=<span class="literal">None</span>, cv=<span class="literal">None</span>, gcv_mode=<span class="literal">None</span>, store_cv_values=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><p><strong>gcv_mode</strong>：{‘auto’, ‘svd’, eigen’}, default=’auto’</p>
<p>指示执行通用交叉验证时使用哪种策略的标志</p>
</li>
</ul>
<h2 id="Lasso回归"><a href="#Lasso回归" class="headerlink" title="Lasso回归"></a>Lasso回归</h2><p><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso"><code>Lasso</code></a> 类的实现使用了 coordinate descent （坐标下降算法）来拟合系数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"></span><br><span class="line">reg = linear_model.Lasso(alpha=<span class="number">0.1</span>)</span><br><span class="line">reg.fit([[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>]], [<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">print(reg.predict([[<span class="number">1</span>, <span class="number">1</span>]]), reg.coef_, reg.intercept_)</span><br></pre></td></tr></table></figure>

<p>对于较简单的任务，同样有用的是函数 <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.lasso_path.html#sklearn.linear_model.lasso_path"><code>lasso_path</code></a> 。它能够通过搜索所有可能的路径上的值来计算系数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Lasso(alpha=<span class="number">1.0</span>, *, fit_intercept=<span class="literal">True</span>, normalize=<span class="literal">False</span>, precompute=<span class="literal">False</span>, copy_X=<span class="literal">True</span>, max_iter=<span class="number">1000</span>, tol=<span class="number">0.0001</span>, warm_start=<span class="literal">False</span>, positive=<span class="literal">False</span>, random_state=<span class="literal">None</span>, selection=<span class="string">&#x27;cyclic&#x27;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>alpha：</strong>float, optional</li>
</ul>
<p>　　正则项参数。常数。默认值1.0。alpha=0时转化为最小二乘估计，由线性回归模型求解。使用Lasso模型时，通常令alpha≠0。</p>
<ul>
<li><strong>fit_intercept：</strong>boolean, optional, default True</li>
</ul>
<p>　　是否计算截距。如果为False，对数据进行去中心化处理。</p>
<ul>
<li><strong>normalize：</strong>boolean, optional, default False</li>
</ul>
<p>　　对数据X进行标准化</p>
<ul>
<li><strong>precompute：</strong>True | False | array-like, default=False</li>
</ul>
<p>　　是否使用事先计算好的Gram矩阵来加速模型计算。如果precompute=’auto’，让程序自动决定。Gram矩阵可以作为参数被传递。对于稀疏数据，通常令precompute=True，保留稀疏性。</p>
<ul>
<li><strong>copy_X：</strong>boolean, optional, default True</li>
</ul>
<p>　　如果copy_X=True，复制X；如果copy_X=False，覆盖上次运行的X。</p>
<ul>
<li><strong>max_iter：</strong>int, optional</li>
</ul>
<p>　　最大迭代次数。</p>
<ul>
<li><strong>tol：</strong>float, optional</li>
</ul>
<p>　　优化容忍度：如果更新大于tol，继续优化，直到小于tol。</p>
<ul>
<li><strong>warm_start：</strong>bool, optional</li>
</ul>
<p>　　如果warm_start=True，使用上次的解作为初始化；如果warm_start=False，清除之前的解。</p>
<ul>
<li><strong>positive：</strong>bool, optional</li>
</ul>
<p>　　如果positive=True，强制将系数设为正数。</p>
<ul>
<li><p><strong>random_state：</strong>int, RandomState instance or None, optional, default None</p>
<p>伪随机数发生器种子，随机选择特征来更新模型。</p>
</li>
<li><p><strong>selection：</strong>str, default ‘cyclic’</p>
<p>如果为‘random’，每次迭代都会更新随机系数，而不是按顺序遍历每个特征。该参数值可以使得算法更快收敛，尤其当tol&gt;1e-4时。</p>
</li>
</ul>

            </div>

            <!-- Post Comments -->
            
    <!-- 使用 DISQUS_CLICK -->
<div id="disqus-comment">
    <div id="disqus_thread"></div>

<!-- add animation -->
<style>
	.disqus_click_btn {
            line-height: 30px;
            margin: 0;
            min-width: 50px;
            padding: 0 14px;
            display: inline-block;
            font-family: "Roboto", "Helvetica", "Arial", sans-serif;
            font-size: 14px;
            font-weight: 400;
            text-transform: uppercase;
            letter-spacing: 0;
            overflow: hidden;
            will-change: box-shadow;
            transition: box-shadow .2s cubic-bezier(.4, 0, 1, 1), background-color .2s cubic-bezier(.4, 0, .2, 1), color .2s cubic-bezier(.4, 0, .2, 1);
            outline: 0;
            cursor: pointer;
            text-decoration: none;
            text-align: center;
            vertical-align: middle;
            border: 0;
            background: rgba(158, 158, 158, .2);
            box-shadow: 0 2px 2px 0 rgba(0, 0, 0, .14), 0 3px 1px -2px rgba(0, 0, 0, .2), 0 1px 5px 0 rgba(0, 0, 0, .12);
            color: #fff;
            background-color: #7EC0EE;
            text-shadow: 0
        }
</style>
	
<div class="btn_click_load" id="disqus_bt"> 
    <button class="disqus_click_btn">点击查看评论</button>
</div>

<!--
<script type="text/javascript">
$('.btn_click_load').click(function() {
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'http-miccall-tech'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    document.getElementById('disqus_bt').style.display = "none";
});
</script>
-->
<script type="text/javascript">
    var disqus_config = function () {
        this.page.url = 'http://yoursite.com/2020/07/29/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/';  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = 'http://yoursite.com/2020/07/29/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
</script>

<script type="text/javascript">
    $('.btn_click_load').click(function() {  //click to load comments
        (function() { // DON'T EDIT BELOW THIS LINE
            var d = document;
            var s = d.createElement('script');
            s.src = '//http-miccall-tech.disqus.com/embed.js';
            s.setAttribute('data-timestamp', + new Date());
            (d.head || d.body).appendChild(s);
        })();
        $('.btn_click_load').css('display','none');
    });
</script>
</div>
<style>
    #disqus-comment{
        background-color: #eee;
        padding: 2pc;
    }
</style>


        </div>
        <!-- Copyright 版权 start -->
                <div id="copyright">
            <ul>
                <li>&copy;Powered By <a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/" style="border-bottom: none;">hexo</a></li>
                <li>Design: <a target="_blank" rel="noopener" href="http://miccall.tech " style="border-bottom: none;">miccall</a></li>
            </ul>
            
                <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
			
        </div>
    </div>
</body>



 	
</html>
